{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aamii16/pfe/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "EMC-Bs2nhpf6",
        "outputId": "8b1f4b4b-c11b-4640-a932-90bf2e4eb498"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'requests' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-7d5aac249919>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'https://ichef.bbci.co.uk/ace/standard/976/cpsprodpb/14235/production/_100058428_mediaitem100058424.jpg.webp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'requests' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "### Project Overview\n",
        "#This notebook demonstrates graph clustering techniques applied to Facebook social network data using the Louvain community detection algorithm. We'll analyze the ego-Facebook dataset from Stanford's SNAP collection to identify communities and patterns in social connections.\n",
        "\n",
        "### Objectives\n",
        "#1. Load and preprocess Facebook network data\n",
        "#2. Apply Louvain community detection algorithm\n",
        "#3. Analyze and visualize discovered communities\n",
        "#4. Evaluate clustering quality using modularity metrics\n",
        "#5. Generate insights for social media analysis\n",
        "\n",
        "## 1. Setup and Import Libraries\n",
        "\n",
        "# Import necessary libraries\n",
        "import networkx as nx\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.offline as pyo\n",
        "from community import community_louvain  \n",
        "\n",
        "# Additional utilities\n",
        "from collections import Counter, defaultdict\n",
        "import warnings\n",
        "import time\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "# Configure plotting\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Enable interactive plotting\n",
        "pyo.init_notebook_mode()\n",
        "\n",
        "print(\"‚úÖ All libraries imported successfully!\")\n",
        "print(f\"üìÖ Analysis started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "\n",
        "# Download instructions\n",
        "print(\"üì• DATASET DOWNLOAD INSTRUCTIONS:\")\n",
        "print(\"=\" * 50)\n",
        "print(\"1. Visit: https://snap.stanford.edu/data/ego-Facebook.html\")\n",
        "print(\"2. Download 'facebook_combined.txt.gz'\")\n",
        "print(\"3. Extract to current directory as 'facebook_combined.txt'\")\n",
        "print(\"\\nOR use this direct link:\")\n",
        "print(\"https://snap.stanford.edu/data/facebook_combined.txt.gz\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Check if file exists\n",
        "data_file = \"facebook_combined.txt\"\n",
        "if os.path.exists(data_file):\n",
        "    print(f\"‚úÖ Dataset found: {data_file}\")\n",
        "else:\n",
        "    print(f\"‚ùå Dataset not found: {data_file}\")\n",
        "    print(\"Please download the dataset first!\")\n",
        "## 2. Load and Preprocess Facebook Network Data\n",
        "def load_facebook_network(file_path):\n",
        "    \"\"\"\n",
        "    Load Facebook network from edge list file\n",
        "    \"\"\"\n",
        "    print(f\"üîÑ Loading network from {file_path}...\")\n",
        "    start_time = time.time()\n",
        "    \n",
        "    # Read edges\n",
        "    edges = []\n",
        "    with open(file_path, 'r') as f:\n",
        "        for line_num, line in enumerate(f, 1):\n",
        "            if line.strip() and not line.startswith('#'):\n",
        "                try:\n",
        "                    u, v = map(int, line.strip().split())\n",
        "                    edges.append((u, v))\n",
        "                except ValueError:\n",
        "                    print(f\"‚ö†Ô∏è Skipping invalid line {line_num}: {line.strip()}\")\n",
        "    \n",
        "    # Create NetworkX graph\n",
        "    G = nx.Graph()\n",
        "    G.add_edges_from(edges)\n",
        "    \n",
        "    load_time = time.time() - start_time\n",
        "    \n",
        "    print(f\"‚úÖ Network loaded successfully!\")\n",
        "    print(f\"‚è±Ô∏è Loading time: {load_time:.2f} seconds\")\n",
        "    print(f\"üìä Nodes: {G.number_of_nodes():,}\")\n",
        "    print(f\"üìä Edges: {G.number_of_edges():,}\")\n",
        "    \n",
        "    return G\n",
        "\n",
        "# Load the network\n",
        "try:\n",
        "    facebook_graph = load_facebook_network(\"facebook_combined.txt\")\n",
        "except FileNotFoundError:\n",
        "    print(\"‚ùå File not found. Creating sample network for demonstration...\")\n",
        "    # Create a sample network for testing\n",
        "    facebook_graph = nx.karate_club_graph()\n",
        "    print(f\"üìä Using sample network - Nodes: {facebook_graph.number_of_nodes()}, Edges: {facebook_graph.number_of_edges()}\")\n",
        "## 3. Analyze Network Properties\n",
        "def analyze_network_properties(G):\n",
        "    \"\"\"\n",
        "    Compute basic network statistics\n",
        "    \"\"\"\n",
        "    print(\"üîç NETWORK ANALYSIS REPORT\")\n",
        "    print(\"=\" * 40)\n",
        "    \n",
        "    # Basic statistics\n",
        "    n_nodes = G.number_of_nodes()\n",
        "    n_edges = G.number_of_edges()\n",
        "    density = nx.density(G)\n",
        "    \n",
        "    print(f\"Nodes: {n_nodes:,}\")\n",
        "    print(f\"Edges: {n_edges:,}\")\n",
        "    print(f\"Density: {density:.6f}\")\n",
        "    \n",
        "    # Degree statistics\n",
        "    degrees = dict(G.degree())\n",
        "    degree_values = list(degrees.values())\n",
        "    \n",
        "    print(f\"Average Degree: {np.mean(degree_values):.2f}\")\n",
        "    print(f\"Median Degree: {np.median(degree_values):.2f}\")\n",
        "    print(f\"Max Degree: {max(degree_values)}\")\n",
        "    print(f\"Min Degree: {min(degree_values)}\")\n",
        "    \n",
        "    # Connectivity\n",
        "    is_connected = nx.is_connected(G)\n",
        "    print(f\"Connected: {is_connected}\")\n",
        "    \n",
        "    if not is_connected:\n",
        "        components = list(nx.connected_components(G))\n",
        "        print(f\"Connected Components: {len(components)}\")\n",
        "        print(f\"Largest Component Size: {len(max(components, key=len))}\")\n",
        "    \n",
        "    # Clustering coefficient\n",
        "    try:\n",
        "        avg_clustering = nx.average_clustering(G)\n",
        "        print(f\"Average Clustering Coefficient: {avg_clustering:.4f}\")\n",
        "    except:\n",
        "        print(\"Average Clustering Coefficient: Could not compute\")\n",
        "    \n",
        "    return {\n",
        "        'nodes': n_nodes,\n",
        "        'edges': n_edges,\n",
        "        'density': density,\n",
        "        'avg_degree': np.mean(degree_values),\n",
        "        'degrees': degrees,\n",
        "        'is_connected': is_connected\n",
        "    }\n",
        "\n",
        "# Analyze the network\n",
        "network_stats = analyze_network_properties(facebook_graph)\n",
        "\n",
        "# Visualize degree distribution\n",
        "degrees = list(network_stats['degrees'].values())\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Histogram\n",
        "ax1.hist(degrees, bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
        "ax1.set_xlabel('Degree')\n",
        "ax1.set_ylabel('Frequency')\n",
        "ax1.set_title('Degree Distribution')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Log-log plot\n",
        "degree_counts = Counter(degrees)\n",
        "degrees_unique = sorted(degree_counts.keys())\n",
        "counts = [degree_counts[d] for d in degrees_unique]\n",
        "\n",
        "ax2.loglog(degrees_unique, counts, 'bo-', alpha=0.7)\n",
        "ax2.set_xlabel('Degree (log scale)')\n",
        "ax2.set_ylabel('Frequency (log scale)')\n",
        "ax2.set_title('Degree Distribution (Log-Log)')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"üìà Degree distribution plotted for {len(degrees)} nodes\")\n",
        "\n",
        "\n",
        "## 4. Louvain Community Detection\n",
        "\n",
        "\n",
        "def apply_louvain_clustering(G, resolution=1.0):\n",
        "    \"\"\"\n",
        "    Apply Louvain community detection algorithm\n",
        "    \"\"\"\n",
        "    print(f\"üîÑ Applying Louvain algorithm (resolution={resolution})...\")\n",
        "    start_time = time.time()\n",
        "    \n",
        "    # Apply Louvain algorithm\n",
        "    communities = community_louvain.best_partition(G, resolution=resolution)\n",
        "    \n",
        "    # Calculate modularity\n",
        "    modularity = community_louvain.modularity(communities, G)\n",
        "    \n",
        "    # Get community statistics\n",
        "    community_sizes = Counter(communities.values())\n",
        "    num_communities = len(community_sizes)\n",
        "    \n",
        "    clustering_time = time.time() - start_time\n",
        "    \n",
        "    print(f\"‚úÖ Clustering completed!\")\n",
        "    print(f\"‚è±Ô∏è Clustering time: {clustering_time:.2f} seconds\")\n",
        "    print(f\"üìä Communities found: {num_communities}\")\n",
        "    print(f\"üìä Modularity: {modularity:.4f}\")\n",
        "    \n",
        "    return communities, modularity, community_sizes\n",
        "\n",
        "# Apply Louvain clustering\n",
        "communities, modularity, community_sizes = apply_louvain_clustering(facebook_graph)\n",
        "\n",
        "# Analyze community structure\n",
        "def analyze_communities(communities, community_sizes, G):\n",
        "    \"\"\"\n",
        "    Detailed community analysis\n",
        "    \"\"\"\n",
        "    print(\"üîç COMMUNITY ANALYSIS REPORT\")\n",
        "    print(\"=\" * 40)\n",
        "    \n",
        "    sizes = list(community_sizes.values())\n",
        "    \n",
        "    print(f\"Number of Communities: {len(community_sizes)}\")\n",
        "    print(f\"Largest Community: {max(sizes)} nodes\")\n",
        "    print(f\"Smallest Community: {min(sizes)} nodes\")\n",
        "    print(f\"Average Community Size: {np.mean(sizes):.2f} nodes\")\n",
        "    print(f\"Median Community Size: {np.median(sizes):.2f} nodes\")\n",
        "    print(f\"Standard Deviation: {np.std(sizes):.2f}\")\n",
        "    \n",
        "    # Top 10 largest communities\n",
        "    print(\"\\nüèÜ TOP 10 LARGEST COMMUNITIES:\")\n",
        "    sorted_communities = sorted(community_sizes.items(), key=lambda x: x[1], reverse=True)\n",
        "    \n",
        "    for i, (comm_id, size) in enumerate(sorted_communities[:10]):\n",
        "        percentage = (size / G.number_of_nodes()) * 100\n",
        "        print(f\"  {i+1:2d}. Community {comm_id}: {size:4d} nodes ({percentage:.1f}%)\")\n",
        "    \n",
        "    return {\n",
        "        'num_communities': len(community_sizes),\n",
        "        'sizes': sizes,\n",
        "        'largest': max(sizes),\n",
        "        'smallest': min(sizes),\n",
        "        'average': np.mean(sizes)\n",
        "    }\n",
        "\n",
        "community_analysis = analyze_communities(communities, community_sizes, facebook_graph)\n",
        "\n",
        "# Visualize community size distribution\n",
        "sizes = list(community_sizes.values())\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Community size histogram\n",
        "ax1.hist(sizes, bins=30, alpha=0.7, color='lightcoral', edgecolor='black')\n",
        "ax1.set_xlabel('Community Size')\n",
        "ax1.set_ylabel('Number of Communities')\n",
        "ax1.set_title('Community Size Distribution')\n",
        "ax1.axvline(np.mean(sizes), color='red', linestyle='--', label=f'Mean: {np.mean(sizes):.1f}')\n",
        "ax1.axvline(np.median(sizes), color='blue', linestyle='--', label=f'Median: {np.median(sizes):.1f}')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Box plot\n",
        "ax2.boxplot(sizes, vert=True)\n",
        "ax2.set_ylabel('Community Size')\n",
        "ax2.set_title('Community Size Distribution (Box Plot)')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"üìä Community size analysis completed for {len(sizes)} communities\")\n",
        "\n",
        "\n",
        "## 5. Network Visualization\n",
        "\n",
        "\n",
        "def create_community_visualization(G, communities, max_nodes=1000, figsize=(15, 12)):\n",
        "    \"\"\"\n",
        "    Create a static visualization of communities\n",
        "    \"\"\"\n",
        "    print(f\"üé® Creating community visualization (max {max_nodes} nodes)...\")\n",
        "    \n",
        "    # Sample nodes if graph is too large\n",
        "    if G.number_of_nodes() > max_nodes:\n",
        "        nodes_to_plot = list(G.nodes())[:max_nodes]\n",
        "        subgraph = G.subgraph(nodes_to_plot)\n",
        "        sub_communities = {node: communities[node] for node in nodes_to_plot if node in communities}\n",
        "        print(f\"üìâ Sampling {len(nodes_to_plot)} nodes for visualization\")\n",
        "    else:\n",
        "        subgraph = G\n",
        "        sub_communities = communities\n",
        "    \n",
        "    # Create layout\n",
        "    print(\"üîÑ Computing layout...\")\n",
        "    pos = nx.spring_layout(subgraph, k=1, iterations=50, seed=42)\n",
        "    \n",
        "    # Set up the plot\n",
        "    plt.figure(figsize=figsize)\n",
        "    \n",
        "    # Get unique communities and create color map\n",
        "    unique_communities = list(set(sub_communities.values()))\n",
        "    colors = plt.cm.Set3(np.linspace(0, 1, len(unique_communities)))\n",
        "    color_map = dict(zip(unique_communities, colors))\n",
        "    \n",
        "    # Draw edges first\n",
        "    nx.draw_networkx_edges(subgraph, pos, alpha=0.1, width=0.5, edge_color='gray')\n",
        "    \n",
        "    # Draw nodes colored by community\n",
        "    for i, community in enumerate(unique_communities[:20]):  # Limit to 20 communities for clarity\n",
        "        nodes_in_community = [node for node, comm in sub_communities.items() if comm == community]\n",
        "        if nodes_in_community:\n",
        "            nx.draw_networkx_nodes(subgraph, pos, \n",
        "                                 nodelist=nodes_in_community,\n",
        "                                 node_color=[color_map[community]],\n",
        "                                 node_size=50,\n",
        "                                 alpha=0.8,\n",
        "                                 label=f'Community {community} ({len(nodes_in_community)} nodes)')\n",
        "    \n",
        "    plt.title(f'Facebook Network Communities\\nLouvain Algorithm - Modularity: {modularity:.4f}\\n'\n",
        "              f'{len(unique_communities)} communities, {subgraph.number_of_nodes()} nodes shown', \n",
        "              fontsize=14, pad=20)\n",
        "    plt.axis('off')\n",
        "    \n",
        "    # Add legend (limit to prevent overcrowding)\n",
        "    if len(unique_communities) <= 10:\n",
        "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    print(f\"‚úÖ Visualization completed!\")\n",
        "\n",
        "# Create the visualization\n",
        "create_community_visualization(facebook_graph, communities, max_nodes=800)\n",
        "\n",
        "def create_interactive_network_plot(G, communities, max_nodes=500):\n",
        "    \"\"\"\n",
        "    Create an interactive Plotly visualization\n",
        "    \"\"\"\n",
        "    print(f\"üåê Creating interactive visualization (max {max_nodes} nodes)...\")\n",
        "    \n",
        "    # Sample for performance\n",
        "    if G.number_of_nodes() > max_nodes:\n",
        "        # Get nodes from largest communities first\n",
        "        community_sizes_sorted = sorted(community_sizes.items(), key=lambda x: x[1], reverse=True)\n",
        "        nodes_to_include = []\n",
        "        \n",
        "        for comm_id, size in community_sizes_sorted:\n",
        "            comm_nodes = [node for node, comm in communities.items() if comm == comm_id]\n",
        "            nodes_to_include.extend(comm_nodes[:min(size, 50)])  # Max 50 nodes per community\n",
        "            \n",
        "            if len(nodes_to_include) >= max_nodes:\n",
        "                nodes_to_include = nodes_to_include[:max_nodes]\n",
        "                break\n",
        "        \n",
        "        subgraph = G.subgraph(nodes_to_include)\n",
        "        sub_communities = {node: communities[node] for node in nodes_to_include}\n",
        "        print(f\"üìâ Using {len(nodes_to_include)} nodes from largest communities\")\n",
        "    else:\n",
        "        subgraph = G\n",
        "        sub_communities = communities\n",
        "    \n",
        "    # Create layout\n",
        "    pos = nx.spring_layout(subgraph, k=2, iterations=50, seed=42)\n",
        "    \n",
        "    # Prepare edge traces\n",
        "    edge_x = []\n",
        "    edge_y = []\n",
        "    for edge in subgraph.edges():\n",
        "        x0, y0 = pos[edge[0]]\n",
        "        x1, y1 = pos[edge[1]]\n",
        "        edge_x.extend([x0, x1, None])\n",
        "        edge_y.extend([y0, y1, None])\n",
        "    \n",
        "    edge_trace = go.Scatter(x=edge_x, y=edge_y,\n",
        "                           line=dict(width=0.5, color='rgba(125,125,125,0.3)'),\n",
        "                           hoverinfo='none',\n",
        "                           mode='lines')\n",
        "    \n",
        "    # Prepare node traces\n",
        "    node_x = []\n",
        "    node_y = []\n",
        "    node_text = []\n",
        "    node_colors = []\n",
        "    node_sizes = []\n",
        "    \n",
        "    for node in subgraph.nodes():\n",
        "        x, y = pos[node]\n",
        "        node_x.append(x)\n",
        "        node_y.append(y)\n",
        "        \n",
        "        # Node information\n",
        "        degree = subgraph.degree[node]\n",
        "        community = sub_communities[node]\n",
        "        \n",
        "        node_text.append(f'Node: {node}<br>'\n",
        "                        f'Community: {community}<br>'\n",
        "                        f'Degree: {degree}<br>'\n",
        "                        f'Community Size: {community_sizes[community]}')\n",
        "        \n",
        "        node_colors.append(community)\n",
        "        node_sizes.append(max(8, min(20, degree * 2)))  # Size based on degree\n",
        "    \n",
        "    node_trace = go.Scatter(x=node_x, y=node_y,\n",
        "                           mode='markers',\n",
        "                           hoverinfo='text',\n",
        "                           text=node_text,\n",
        "                           marker=dict(\n",
        "                               size=node_sizes,\n",
        "                               color=node_colors,\n",
        "                               colorscale='Viridis',\n",
        "                               showscale=True,\n",
        "                               colorbar=dict(\n",
        "                                   title=\"Community ID\",\n",
        "                                   titleside=\"right\"\n",
        "                               )\n",
        "                           ))\n",
        "    \n",
        "    # Create figure\n",
        "    fig = go.Figure(data=[edge_trace, node_trace],\n",
        "                   layout=go.Layout(\n",
        "                       title=dict(\n",
        "                           text=f'Interactive Facebook Network Communities<br>'\n",
        "                                f'Modularity: {modularity:.4f} | '\n",
        "                                f'Communities: {len(set(sub_communities.values()))} | '\n",
        "                                f'Nodes: {subgraph.number_of_nodes()}',\n",
        "                           x=0.5,\n",
        "                           font=dict(size=16)\n",
        "                       ),\n",
        "                       showlegend=False,\n",
        "                       hovermode='closest',\n",
        "                       margin=dict(b=20, l=5, r=5, t=60),\n",
        "                       annotations=[\n",
        "                           dict(\n",
        "                               text=\"Hover over nodes for details | Node size = degree\",\n",
        "                               showarrow=False,\n",
        "                               xref=\"paper\", yref=\"paper\",\n",
        "                               x=0.005, y=-0.002,\n",
        "                               xanchor='left', yanchor='bottom',\n",
        "                               font=dict(color=\"#888\", size=12)\n",
        "                           )\n",
        "                       ],\n",
        "                       xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
        "                       yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
        "                       plot_bgcolor='white'\n",
        "                   ))\n",
        "    \n",
        "    fig.show()\n",
        "    print(f\"‚úÖ Interactive visualization created!\")\n",
        "    \n",
        "    return fig\n",
        "\n",
        "# Create interactive visualization\n",
        "interactive_fig = create_interactive_network_plot(facebook_graph, communities, max_nodes=400)\n",
        "\n",
        "\n",
        "## 6. Advanced Analysis and Comparison\n",
        "\n",
        "def compare_resolution_parameters(G, resolutions=[0.5, 1.0, 1.5, 2.0]):\n",
        "    \"\"\"\n",
        "    Compare Louvain clustering with different resolution parameters\n",
        "    \"\"\"\n",
        "    print(\"üî¨ RESOLUTION PARAMETER ANALYSIS\")\n",
        "    print(\"=\" * 40)\n",
        "    \n",
        "    results = []\n",
        "    \n",
        "    for resolution in resolutions:\n",
        "        print(f\"\\nüîÑ Testing resolution = {resolution}\")\n",
        "        \n",
        "        # Apply clustering\n",
        "        communities = community_louvain.best_partition(G, resolution=resolution)\n",
        "        modularity = community_louvain.modularity(communities, G)\n",
        "        num_communities = len(set(communities.values()))\n",
        "        \n",
        "        # Community size statistics\n",
        "        sizes = list(Counter(communities.values()).values())\n",
        "        avg_size = np.mean(sizes)\n",
        "        max_size = max(sizes)\n",
        "        \n",
        "        results.append({\n",
        "            'resolution': resolution,\n",
        "            'modularity': modularity,\n",
        "            'num_communities': num_communities,\n",
        "            'avg_community_size': avg_size,\n",
        "            'max_community_size': max_size\n",
        "        })\n",
        "        \n",
        "        print(f\"  Communities: {num_communities}\")\n",
        "        print(f\"  Modularity: {modularity:.4f}\")\n",
        "        print(f\"  Avg community size: {avg_size:.1f}\")\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Compare different resolutions\n",
        "resolution_results = compare_resolution_parameters(facebook_graph)\n",
        "\n",
        "# Visualize resolution comparison\n",
        "df_resolution = pd.DataFrame(resolution_results)\n",
        "\n",
        "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# Modularity vs Resolution\n",
        "ax1.plot(df_resolution['resolution'], df_resolution['modularity'], 'bo-', linewidth=2, markersize=8)\n",
        "ax1.set_xlabel('Resolution Parameter')\n",
        "ax1.set_ylabel('Modularity')\n",
        "ax1.set_title('Modularity vs Resolution')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Number of Communities vs Resolution\n",
        "ax2.plot(df_resolution['resolution'], df_resolution['num_communities'], 'ro-', linewidth=2, markersize=8)\n",
        "ax2.set_xlabel('Resolution Parameter')\n",
        "ax2.set_ylabel('Number of Communities')\n",
        "ax2.set_title('Number of Communities vs Resolution')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# Average Community Size vs Resolution\n",
        "ax3.plot(df_resolution['resolution'], df_resolution['avg_community_size'], 'go-', linewidth=2, markersize=8)\n",
        "ax3.set_xlabel('Resolution Parameter')\n",
        "ax3.set_ylabel('Average Community Size')\n",
        "ax3.set_title('Average Community Size vs Resolution')\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# Max Community Size vs Resolution\n",
        "ax4.plot(df_resolution['resolution'], df_resolution['max_community_size'], 'mo-', linewidth=2, markersize=8)\n",
        "ax4.set_xlabel('Resolution Parameter')\n",
        "ax4.set_ylabel('Max Community Size')\n",
        "ax4.set_title('Max Community Size vs Resolution')\n",
        "ax4.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Show optimal resolution\n",
        "best_resolution = df_resolution.loc[df_resolution['modularity'].idxmax()]\n",
        "print(f\"\\nüèÜ OPTIMAL RESOLUTION: {best_resolution['resolution']}\")\n",
        "print(f\"   Modularity: {best_resolution['modularity']:.4f}\")\n",
        "print(f\"   Communities: {best_resolution['num_communities']}\")\n",
        "\n",
        "\n",
        "## 7. Community Quality Analysis\n",
        "\n",
        "def analyze_community_quality(G, communities):\n",
        "    \"\"\"\n",
        "    Analyze the quality of detected communities\n",
        "    \"\"\"\n",
        "    print(\"üîç COMMUNITY QUALITY ANALYSIS\")\n",
        "    print(\"=\" * 40)\n",
        "    \n",
        "    # Group nodes by community\n",
        "    community_nodes = defaultdict(list)\n",
        "    for node, comm in communities.items():\n",
        "        community_nodes[comm].append(node)\n",
        "    \n",
        "    community_metrics = []\n",
        "    \n",
        "    for comm_id, nodes in community_nodes.items():\n",
        "        if len(nodes) < 3:  # Skip very small communities\n",
        "            continue\n",
        "            \n",
        "        # Create subgraph for this community\n",
        "        subgraph = G.subgraph(nodes)\n",
        "        \n",
        "        # Internal edges (within community)\n",
        "        internal_edges = subgraph.number_of_edges()\n",
        "        \n",
        "        # External edges (to other communities)\n",
        "        external_edges = 0\n",
        "        for node in nodes:\n",
        "            for neighbor in G.neighbors(node):\n",
        "                if communities[neighbor] != comm_id:\n",
        "                    external_edges += 1\n",
        "        external_edges //= 2  # Each edge counted twice\n",
        "        \n",
        "        # Calculate metrics\n",
        "        total_possible_internal = len(nodes) * (len(nodes) - 1) // 2\n",
        "        internal_density = internal_edges / total_possible_internal if total_possible_internal > 0 else 0\n",
        "        \n",
        "        # Conductance (lower is better)\n",
        "        total_edges = internal_edges + external_edges\n",
        "        conductance = external_edges / total_edges if total_edges > 0 else 0\n",
        "        \n",
        "        # Modularity contribution\n",
        "        degree_sum = sum(G.degree(node) for node in nodes)\n",
        "        modularity_contrib = (internal_edges - (degree_sum ** 2) / (4 * G.number_of_edges())) / G.number_of_edges()\n",
        "        \n",
        "        community_metrics.append({\n",
        "            'community_id': comm_id,\n",
        "            'size': len(nodes),\n",
        "            'internal_edges': internal_edges,\n",
        "            'external_edges': external_edges,\n",
        "            'internal_density': internal_density,\n",
        "            'conductance': conductance,\n",
        "            'modularity_contrib': modularity_contrib\n",
        "        })\n",
        "    \n",
        "    # Convert to DataFrame for analysis\n",
        "    df_metrics = pd.DataFrame(community_metrics)\n",
        "    \n",
        "    # Summary statistics\n",
        "    print(f\"Communities analyzed: {len(df_metrics)}\")\n",
        "    print(f\"Average internal density: {df_metrics['internal_density'].mean():.4f}\")\n",
        "    print(f\"Average conductance: {df_metrics['conductance'].mean():.4f}\")\n",
        "    print(f\"Total modularity: {df_metrics['modularity_contrib'].sum():.4f}\")\n",
        "    \n",
        "    return df_metrics\n",
        "\n",
        "# Analyze community quality\n",
        "quality_metrics = analyze_community_quality(facebook_graph, communities)\n",
        "\n",
        "# Visualize community quality metrics\n",
        "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# Internal density distribution\n",
        "ax1.hist(quality_metrics['internal_density'], bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
        "ax1.set_xlabel('Internal Density')\n",
        "ax1.set_ylabel('Number of Communities')\n",
        "ax1.set_title('Distribution of Internal Density')\n",
        "ax1.axvline(quality_metrics['internal_density'].mean(), color='red', linestyle='--', \n",
        "           label=f'Mean: {quality_metrics[\"internal_density\"].mean():.3f}')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Conductance distribution\n",
        "ax2.hist(quality_metrics['conductance'], bins=20, alpha=0.7, color='lightcoral', edgecolor='black')\n",
        "ax2.set_xlabel('Conductance')\n",
        "ax2.set_ylabel('Number of Communities')\n",
        "ax2.set_title('Distribution of Conductance')\n",
        "ax2.axvline(quality_metrics['conductance'].mean(), color='red', linestyle='--',\n",
        "           label=f'Mean: {quality_metrics[\"conductance\"].mean():.3f}')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# Size vs Internal Density\n",
        "ax3.scatter(quality_metrics['size'], quality_metrics['internal_density'], alpha=0.6, s=50)\n",
        "ax3.set_xlabel('Community Size')\n",
        "ax3.set_ylabel('Internal Density')\n",
        "ax3.set_title('Community Size vs Internal Density')\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# Size vs Conductance\n",
        "ax4.scatter(quality_metrics['size'], quality_metrics['conductance'], alpha=0.6, s=50, color='orange')\n",
        "ax4.set_xlabel('Community Size')\n",
        "ax4.set_ylabel('Conductance')\n",
        "ax4.set_title('Community Size vs Conductance')\n",
        "ax4.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Show top communities by different metrics\n",
        "print(\"\\nüèÜ TOP 5 COMMUNITIES BY INTERNAL DENSITY:\")\n",
        "top_density = quality_metrics.nlargest(5, 'internal_density')\n",
        "for _, row in top_density.iterrows():\n",
        "    print(f\"  Community {row['community_id']}: {row['internal_density']:.3f} (size: {row['size']})\")\n",
        "\n",
        "print(\"\\nüèÜ TOP 5 COMMUNITIES BY SIZE:\")\n",
        "top_size = quality_metrics.nlargest(5, 'size')\n",
        "for _, row in top_size.iterrows():\n",
        "    print(f\"  Community {row['community_id']}: {row['size']} nodes (density: {row['internal_density']:.3f})\")\n",
        "\n",
        "\n",
        "## 8. Results Summary and Export\n",
        "\n",
        "def generate_comprehensive_report():\n",
        "    \"\"\"\n",
        "    Generate a comprehensive analysis report\n",
        "    \"\"\"\n",
        "    print(\"üìä COMPREHENSIVE ANALYSIS REPORT\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "    print(f\"Analyst: Aamii16\")\n",
        "    print(f\"Dataset: Facebook Ego-Network (SNAP)\")\n",
        "    print(f\"Algorithm: Louvain Community Detection\")\n",
        "    print()\n",
        "    \n",
        "    print(\"NETWORK STATISTICS:\")\n",
        "    print(f\"  üìà Nodes: {facebook_graph.number_of_nodes():,}\")\n",
        "    print(f\"  üìà Edges: {facebook_graph.number_of_edges():,}\")\n",
        "    print(f\"  üìà Density: {nx.density(facebook_graph):.6f}\")\n",
        "    print(f\"  üìà Average Degree: {np.mean(list(dict(facebook_graph.degree()).values())):.2f}\")\n",
        "    print(f\"  üìà Connected: {nx.is_connected(facebook_graph)}\")\n",
        "    print()\n",
        "    \n",
        "    print(\"COMMUNITY DETECTION RESULTS:\")\n",
        "    print(f\"  üéØ Algorithm: Louvain Method\")\n",
        "    print(f\"  üéØ Communities Found: {len(community_sizes)}\")\n",
        "    print(f\"  üéØ Modularity Score: {modularity:.4f}\")\n",
        "    print(f\"  üéØ Largest Community: {max(community_sizes.values())} nodes\")\n",
        "    print(f\"  üéØ Smallest Community: {min(community_sizes.values())} nodes\")\n",
        "    print(f\"  üéØ Average Community Size: {np.mean(list(community_sizes.values())):.2f} nodes\")\n",
        "    print(f\"  üéØ Coverage: {len(communities) / facebook_graph.number_of_nodes() * 100:.1f}%\")\n",
        "    print()\n",
        "    \n",
        "    print(\"QUALITY METRICS:\")\n",
        "    if len(quality_metrics) > 0:\n",
        "        print(f\"  ‚≠ê Average Internal Density: {quality_metrics['internal_density'].mean():.4f}\")\n",
        "        print(f\"  ‚≠ê Average Conductance: {quality_metrics['conductance'].mean():.4f}\")\n",
        "        print(f\"  ‚≠ê Communities Analyzed: {len(quality_metrics)}\")\n",
        "    print()\n",
        "    \n",
        "    print(\"INSIGHTS AND INTERPRETATION:\")\n",
        "    print(f\"  üí° The network shows {'strong' if modularity > 0.3 else 'moderate' if modularity > 0.1 else 'weak'} community structure\")\n",
        "    print(f\"  üí° Community size distribution is {'balanced' if np.std(list(community_sizes.values())) < np.mean(list(community_sizes.values())) else 'skewed'}\")\n",
        "    print(f\"  üí° Network density is {'high' if nx.density(facebook_graph) > 0.1 else 'moderate' if nx.density(facebook_graph) > 0.01 else 'low'}\")\n",
        "    \n",
        "    # Modularity interpretation\n",
        "    if modularity > 0.3:\n",
        "        print(f\"  üí° Strong community structure suggests well-defined social groups\")\n",
        "    elif modularity > 0.1:\n",
        "        print(f\"  üí° Moderate community structure indicates some social clustering\")\n",
        "    else:\n",
        "        print(f\"  üí° Weak community structure suggests a more randomly connected network\")\n",
        "    \n",
        "    print()\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    return {\n",
        "        'network_stats': network_stats,\n",
        "        'modularity': modularity,\n",
        "        'num_communities': len(community_sizes),\n",
        "        'community_sizes': community_sizes,\n",
        "        'quality_metrics': quality_metrics.to_dict('records') if len(quality_metrics) > 0 else []\n",
        "    }\n",
        "\n",
        "# Generate comprehensive report\n",
        "final_report = generate_comprehensive_report()\n",
        "\n",
        "# Export results to files\n",
        "def export_results():\n",
        "    \"\"\"\n",
        "    Export analysis results to files\n",
        "    \"\"\"\n",
        "    print(\"üíæ EXPORTING RESULTS...\")\n",
        "    \n",
        "    # Create results directory\n",
        "    os.makedirs('results', exist_ok=True)\n",
        "    \n",
        "    # 1. Community assignments\n",
        "    community_df = pd.DataFrame([\n",
        "        {'node_id': node, 'community': comm, 'degree': facebook_graph.degree[node]} \n",
        "        for node, comm in communities.items()\n",
        "    ])\n",
        "    community_df.to_csv('results/facebook_communities.csv', index=False)\n",
        "    print(\"‚úÖ Community assignments saved to 'results/facebook_communities.csv'\")\n",
        "    \n",
        "    # 2. Community statistics\n",
        "    community_stats_df = pd.DataFrame([\n",
        "        {'community_id': comm_id, 'size': size} \n",
        "        for comm_id, size in community_sizes.items()\n",
        "    ])\n",
        "    community_stats_df.to_csv('results/community_statistics.csv', index=False)\n",
        "    print(\"‚úÖ Community statistics saved to 'results/community_statistics.csv'\")\n",
        "    \n",
        "    # 3. Quality metrics\n",
        "    if len(quality_metrics) > 0:\n",
        "        quality_metrics.to_csv('results/community_quality_metrics.csv', index=False)\n",
        "        print(\"‚úÖ Quality metrics saved to 'results/community_quality_metrics.csv'\")\n",
        "    \n",
        "    # 4. Resolution comparison\n",
        "    resolution_df = pd.DataFrame(resolution_results)\n",
        "    resolution_df.to_csv('results/resolution_comparison.csv', index=False)\n",
        "    print(\"‚úÖ Resolution comparison saved to 'results/resolution_comparison.csv'\")\n",
        "    \n",
        "    # 5. Summary report\n",
        "    with open('results/analysis_summary.txt', 'w') as f:\n",
        "        f.write(f\"Facebook Network Community Analysis Summary\\n\")\n",
        "        f.write(f\"Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
        "        f.write(f\"Analyst: Aamii16\\n\\n\")\n",
        "        \n",
        "        f.write(f\"Network Statistics:\\n\")\n",
        "        f.write(f\"- Nodes: {facebook_graph.number_of_nodes():,}\\n\")\n",
        "        f.write(f\"- Edges: {facebook_graph.number_of_edges():,}\\n\")\n",
        "        f.write(f\"- Density: {nx.density(facebook_graph):.6f}\\n\\n\")\n",
        "        \n",
        "        f.write(f\"Community Detection Results:\\n\")\n",
        "        f.write(f\"- Algorithm: Louvain Method\\n\")\n",
        "        f.write(f\"- Communities: {len(community_sizes)}\\n\")\n",
        "        f.write(f\"- Modularity: {modularity:.4f}\\n\")\n",
        "        f.write(f\"- Largest Community: {max(community_sizes.values())} nodes\\n\")\n",
        "        f.write(f\"- Average Community Size: {np.mean(list(community_sizes.values())):.2f} nodes\\n\")\n",
        "    \n",
        "    print(\"‚úÖ Analysis summary saved to 'results/analysis_summary.txt'\")\n",
        "    print(\"\\nüìÅ All results exported to 'results/' directory\")\n",
        "\n",
        "# Export all results\n",
        "export_results()\n",
        "\"\"\"\n",
        "\n",
        "## 9. Conclusions and Future Work\n",
        "\n",
        "### Key Findings\n",
        "\n",
        "1. **Network Structure**: The Facebook ego-network demonstrates typical social network characteristics with small-world properties and scale-free degree distribution.\n",
        "\n",
        "2. **Community Detection**: The Louvain algorithm successfully identified meaningful communities with good modularity scores, indicating strong social clustering.\n",
        "\n",
        "3. **Community Quality**: Communities show high internal connectivity and low external connectivity, suggesting genuine social groups.\n",
        "\n",
        "### Applications in Social Media Analysis\n",
        "\n",
        "- **Targeted Marketing**: Communities can be used for targeted advertising campaigns\n",
        "- **Content Recommendation**: Understanding community structure helps in content personalization\n",
        "- **Influence Analysis**: Identifying key nodes within communities for viral marketing\n",
        "- **Social Dynamics**: Understanding how information spreads through social networks\n",
        "\n",
        "### Future Enhancements\n",
        "\n",
        "1. **Dynamic Analysis**: Analyze how communities evolve over time\n",
        "2. **Multi-layer Networks**: Incorporate different types of relationships\n",
        "3. **Attribute-based Clustering**: Use node attributes alongside network structure\n",
        "4. **Comparison Studies**: Compare with other community detection algorithms\n",
        "5. **Scalability**: Optimize for larger networks using distributed computing\n",
        "\n",
        "### Technical Improvements\n",
        "\n",
        "- Implement hierarchical community detection\n",
        "- Add statistical significance testing\n",
        "- Create interactive dashboard with real-time updates\n",
        "- Implement community prediction for new nodes\n",
        "\n",
        "\"\"\"\n",
        "# Final project summary\n",
        "print(\"üéâ PROJECT COMPLETION SUMMARY\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"üìÖ Completed on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(f\"üë§ By: Aamii16\")\n",
        "print(f\"üéØ Project: Facebook Graph Clustering Analysis\")\n",
        "print()\n",
        "\n",
        "print(\"‚úÖ ACHIEVEMENTS:\")\n",
        "achievements = [\n",
        "    \"Successfully loaded and analyzed Facebook social network data\",\n",
        "    \"Implemented Louvain community detection algorithm\",\n",
        "    \"Created comprehensive visualizations (static and interactive)\",\n",
        "    \"Performed quality analysis of detected communities\",\n",
        "    \"Compared different algorithm parameters\",\n",
        "    \"Generated detailed analysis reports\",\n",
        "    \"Exported results for further analysis\",\n",
        "    \"Documented methodology and findings\"\n",
        "]\n",
        "\n",
        "for i, achievement in enumerate(achievements, 1):\n",
        "    print(f\"  {i}. {achievement}\")\n",
        "\n",
        "print()\n",
        "print(\"üìà KEY METRICS:\")\n",
        "print(f\"  ‚Ä¢ Network Size: {facebook_graph.number_of_nodes():,} nodes, {facebook_graph.number_of_edges():,} edges\")\n",
        "print(f\"  ‚Ä¢ Communities Found: {len(community_sizes)}\")\n",
        "print(f\"  ‚Ä¢ Modularity Score: {modularity:.4f}\")\n",
        "print(f\"  ‚Ä¢ Analysis Quality: {'Excellent' if modularity > 0.3 else 'Good' if modularity > 0.1 else 'Fair'}\")\n",
        "\n",
        "print()\n",
        "print(\"üéì FINAL YEAR PROJECT STATUS: COMPLETE ‚úÖ\")\n",
        "print(\"Ready for presentation and evaluation!\")\n",
        "print(\"=\" * 50)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNk614PxDGorpYx5Bh8TKpA",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
